{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import pickle\n",
    "from PIL import Image\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy import stats\n",
    "from numpy.random import randint,randn,standard_normal,random_sample\n",
    "from plotly.offline import plot\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "logmin=-.85\n",
    "import plotly.graph_objects as go\n",
    "def funcsig(w,X,b): # sigmoid functions\n",
    "    return 1/(1+np.exp(-np.matmul(w.transpose(),X)+b))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lossFun(w,M,X,b,lam):\n",
    "    yi=X[:,-1]\n",
    "    X=X[:,:-1].transpose()\n",
    "    h=funcsig(w,X,b)\n",
    "    for val in h:\n",
    "        if(val>logmax):\n",
    "            val=logmax\n",
    "        if(val<logmin):\n",
    "            val=logmin\n",
    "    reg=(lam/2)*np.matmul(w.transpose(),w)\n",
    "    L= -(1/M)*np.sum((np.multiply(yi,np.log(h)))+(np.multiply(1-yi,np.log(1-h)))) + reg\n",
    "    return L\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grayscale(data, dtype='float32'):\n",
    "    # luma coding weighted average in video systems\n",
    "    r, g, b = np.asarray(.3, dtype=dtype), np.asarray(.59, dtype=dtype), np.asarray(.11, dtype=dtype)\n",
    "    rst = r * data[:, :, :, 0] + g * data[:, :, :, 1] + b * data[:, :, :, 2]\n",
    "    # add channel dimension\n",
    "    rst = np.expand_dims(rst, axis=3)\n",
    "    return rst\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    with open(file,'rb') as fo:\n",
    "        dict= pickle.load(fo,encoding ='latin1')\n",
    "    return dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient(w,M,X,b,lam):\n",
    "    yi=X[:,-1]\n",
    "    X=X[:,:-1].transpose()\n",
    "    h=funcsig(w,X,b)\n",
    "    for val in h:\n",
    "        if(val>logmax):\n",
    "            val=logmax\n",
    "        if(val<logmin):\n",
    "            val=logmin\n",
    "    X=X.transpose()\n",
    "    return -(1./M)*np.matmul((yi-h).transpose(),X)+(lam*w)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradientb(w,M,X,b,lam):\n",
    "    yi=X[:,-1]\n",
    "    X=X[:,:-1].transpose()\n",
    "    h=funcsig(w,X,b)\n",
    "    return np.sum(yi-h)/M\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_sample(w,X,b,weightclass):\n",
    "    yi=X[-1]\n",
    "    X=X[:-1].transpose()\n",
    "    h=funcsig(w,X,b)\n",
    "    return h\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradientDescent(w,M,X,b,iters,lr,lam):\n",
    "    for x in range(iters):\n",
    "        L=lossFun(w,M,X,b,lam)\n",
    "        G=gradient(w,M,X,b,lam)\n",
    "        B=gradientb(w,M,X,b,lam)\n",
    "        w=w-(lr*G)\n",
    "        b=b-(lr*B)\n",
    "        print(\"Loss After GD Update \"+ str(x) + \" is \" + str(L))\n",
    "    return w,b\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linClass(X,Y):\n",
    "    w=np.random.standard_normal(1024)\n",
    "    b=random_sample()\n",
    "    X=np.concatenate((X,Y.T.reshape(50000,1)),axis=1)\n",
    "    w,b=gradientDescent(w,50000,X,b,100,10,1e-2)\n",
    "    return w,b\n",
    "    #print(w)## loss becomes around .3333\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "b1=unpickle('cifar-10-batches-py/data_batch_1')\n",
    "b2=unpickle('cifar-10-batches-py/data_batch_2')\n",
    "b3=unpickle('cifar-10-batches-py/data_batch_3')\n",
    "b4=unpickle('cifar-10-batches-py/data_batch_4')\n",
    "b5=unpickle('cifar-10-batches-py/data_batch_5')\n",
    "meta=unpickle('cifar-10-batches-py/batches.meta')\n",
    "tb=unpickle('cifar-10-batches-py/test_batch')\n",
    "\n",
    "label_names=['label_names']\n",
    "\n",
    "join_data= np.concatenate((b1['data'],b2['data'],b3['data'],b4['data'],b5['data']))\n",
    "join_labels= np.concatenate((b1['labels'],b2['labels'],b3['labels'],b4['labels'],b5['labels']))\n",
    "#\n",
    "#test_data= np.concatenate((tb['data']))\n",
    "#test_labels=np.concatenate((tb['labels']))\n",
    "\n",
    "\n",
    "test_data= tb['data']\n",
    "test_labels=tb['labels']\n",
    "\n",
    "join_datargb=join_data.reshape(50000, 3, 32, 32).transpose(0,2,3,1).astype(\"uint8\")\n",
    "join_datagray=grayscale(join_datargb).reshape(50000,1024)\n",
    "#join_data_normalized=stats.zscore(join_datagray,axis=1)  \n",
    "join_data_normalized=normalize(join_datagray,axis=1)  \n",
    "\n",
    "#print(join_data_normalized)\n",
    "    \n",
    "        \n",
    "# X_folds=np.array_split(join_data_normalized,5) # split into five folds\n",
    "# y_folds=np.array_split(join_labels,5)\n",
    "linelist=[]\n",
    "for i in range(0,10):\n",
    "    new_labels=np.copy(join_labels)\n",
    "    for c,v in enumerate(new_labels):\n",
    "        if(v==i):\n",
    "            new_labels[c]=1\n",
    "        else:\n",
    "            new_labels[c]=0\n",
    "    print(\"Traning Classifier with class \"+ str(i))\n",
    "    w,b=linClass(join_data_normalized,new_labels)\n",
    "    linelist.append([w,b])\n",
    "            \n",
    "    \n",
    "            \n",
    "            \n",
    "\n",
    "#print(join_data_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c,wvs in enumerate(linelist):\n",
    "    imgdata=wvs[0].reshape(32,32)\n",
    "    print(imgdata)\n",
    "    #imgdata=imgdata/\n",
    "    plt.imshow(imgdata)\n",
    "    plt.savefig('classifier'+str(c)+'.jpg')\n",
    "    #img = Image.fromarray(imgdata,mode='L')\n",
    "    #img.show()\n",
    "    #img.save('classifier'+str(c)+'.jpg')\n",
    "    #img.show()\n",
    "    \n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_data= tb['data']\n",
    "test_labels=np.array(tb['labels'])\n",
    "\n",
    "test_datargb=test_data.reshape(10000, 3, 32, 32).transpose(0,2,3,1).astype(\"uint8\")\n",
    "test_datagray=grayscale(test_datargb).reshape(10000,1024)\n",
    "X=normalize(test_datagray,axis=1)\n",
    "probvect=[]\n",
    "for samp in X:# loop thrhough Test examples\n",
    "    probclass=[]\n",
    "    #print(X.shape)\n",
    "    for c,wvs in enumerate(linelist): #loop through all weight vectors\n",
    "        wv=np.array(wvs[0])\n",
    "        b=wvs[1]\n",
    "        prob=funcsig(wv,samp,b)\n",
    "        probclass.append(prob)\n",
    "    probvect.append(probclass)\n",
    "    \n",
    "print(probvect)\n",
    "    \n",
    "\n",
    "    \n",
    "   \n",
    "\n",
    "        \n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_accuracies=[]\n",
    "print(len(linelist))\n",
    "for c,wvs in enumerate(linelist):#loop through all weight vectors\n",
    "        corrclass=0\n",
    "        wv=np.array(wvs[0])\n",
    "        b=wvs[1]\n",
    "        for count,samp in enumerate(X):\n",
    "            prob=funcsig(wv,samp,b)\n",
    "            #print(prob)\n",
    "            if(prob>.49999999 and test_labels[count]==c):##correctly guesss this class\n",
    "                corrclass+=1\n",
    "            elif(prob<.49999999 and test_labels[count]!=c):\n",
    "                corrclass+=1\n",
    "        classification_accuracies.append(corrclass/10000)\n",
    "print(classification_accuracies)\n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm=(10,10)\n",
    "cm=np.zeros(cm)\n",
    "print(cm)\n",
    "for sam,probs in enumerate(probvect):\n",
    "    cm[test_labels[sam],np.argmax(probs)]+=1\n",
    "print(cm)\n",
    "\n",
    "accuracy=np.sum(cm.diagonal())/100 # diagonal of array is correctly classified example\n",
    "\n",
    "print(\"Total Accuracy is \"+ str(accuracy) +\"%\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
